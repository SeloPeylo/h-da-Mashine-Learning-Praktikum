{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeloPeylo/h-da-Mashine-Learning-Praktikum/blob/master/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX_h-5dWyhXs",
        "colab_type": "text"
      },
      "source": [
        "## Importing and Processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI9U_2P3gnZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as skl\n",
        "from sklearn.preprocessing import Imputer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, linear_model, preprocessing\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "#Import Data\n",
        "namelist = pd.read_csv('https://gist.githubusercontent.com/naska29/4533e932eba2020f00b2dc826bfed1d0/raw/f757814b823a68324e7d8a4ff25e3fa2612a8e30/communities.namelist', header = None) #import list for the column names\n",
        "datapd = pd.read_csv('https://gist.githubusercontent.com/naska29/7c031b27068e263ea71b36dbe6ae9e83/raw/693755cf101f6486bc5ed63bf412670892e25f3f/communities.data', header = None)\n",
        "datapd.columns = namelist.iloc[:,0] #Naming the columns\n",
        "datapd = skl.utils.shuffle(datapd) #Shuffle the Data rows before Splitting\n",
        "datapd.to_csv('lab02rawdata.csv')\n",
        "\n",
        "#Preprocessing\n",
        "datay = datapd['ViolentCrimesPerPop']\n",
        "datapd = datapd.replace(['?'], [np.nan])\n",
        "\n",
        "#Top 15 features in correlation to ViolentCrimesPerPop\n",
        "data = datapd #Backup Before Selecting relevant Columns\n",
        "#datapd = datapd.iloc[:,5:99]\n",
        "\n",
        "datapd = datapd[['PctIlleg',  \n",
        "                'racepctblack', \n",
        "                'pctWPubAsst',\n",
        "                'FemalePctDiv',\n",
        "                'TotalPctDiv',\n",
        "                'MalePctDivorce',\n",
        "                'PctPersDenseHous',\n",
        "                'NumIlleg',\n",
        "                'PctHousLess3BR']]\n",
        "\n",
        "print(datapd)\n",
        "datapd = datapd.loc[:,(datapd.dtypes == np.float64)|(datapd.dtypes == np.int64)]\n",
        "imp = skl.preprocessing.Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
        "imp.fit(datapd)\n",
        "datax = imp.transform(datapd)\n",
        "datax = pd.DataFrame(datapd)\n",
        "  \n",
        "#print('This is Y:\\n', datay)\n",
        "#print('This is X:\\n', datax)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSH1BJZUxW9b",
        "colab_type": "text"
      },
      "source": [
        "## **Correlations of Features with Object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Vn1mBPxUrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"Correlation:\", datapd.corr(datapd['ViolentCrimesPerPop']))\n",
        "correlations = data[data.columns[1:]].corr()['ViolentCrimesPerPop'][:-1]\n",
        "correlations = correlations.sort_values(ascending=True, axis=0)\n",
        "print(correlations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HImYSmUOytbk",
        "colab_type": "text"
      },
      "source": [
        "## Splits the original sample in Training-set and Test-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAy6KvC7leRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting in Training and Test Datasets\n",
        "trainrows = int(len(datax)*0.6)\n",
        "print('Data Splits at row #', trainrows)\n",
        "xtrain = datax.iloc[:trainrows,:]\n",
        "xtest = datax.iloc[trainrows:,:]\n",
        "ytrain = datay.iloc[:trainrows]\n",
        "ytest = datay.iloc[trainrows:]\n",
        "\n",
        "xtrain.to_csv('lab02xtrain.csv')\n",
        "xtest.to_csv('lab02xtest.csv')\n",
        "ytrain.to_csv('lab02ytrain.csv')\n",
        "ytest.to_csv('lab02ytest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaiHw80my4lU",
        "colab_type": "text"
      },
      "source": [
        "## Training linear regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr9JkWw1lsFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(xtrain, ytrain)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "crimes_y_pred = regr.predict(xtest)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(ytest, crimes_y_pred))\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(ytest, crimes_y_pred), ' #Accuracy')\n",
        "\n",
        "# Plot outputs\n",
        "#plt.scatter(xtest['population'], ytest,  color='black')\n",
        "#plt.plot(xtest['population'], crimes_y_pred, color='blue', linewidth=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1Yt_kP_zF30",
        "colab_type": "text"
      },
      "source": [
        "## Building Model using polynomial Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP2dVLS4l_Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "degrees = [1,2,4,6,8]\n",
        "print(degrees)\n",
        "mse_list = []\n",
        "r2_list = []\n",
        "\n",
        "for i in range(len(degrees)):\n",
        "    #ax = plt.subplot(len(degrees), 1, i + 1)\n",
        "    #plt.setp(ax, xticks=(), yticks=())\n",
        "\n",
        "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
        "                                             include_bias=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    \n",
        "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                         (\"linear_regression\", linear_regression)])\n",
        "    pipeline.fit(xtrain, ytrain)\n",
        "    y_pred = pipeline.predict(xtest)\n",
        "    \n",
        "    #plt.subplot(1,2,1)\n",
        "    #plt.plot(y_pred)\n",
        "    \n",
        "    #plt.subplot(1,2,2)\n",
        "    #plt.plot(ytest)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "    # Evaluate the models using crossvalidation\n",
        "    #scores = cross_val_score(pipeline, xtrain[:, np.newaxis], ytrain,\n",
        "    #                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "    mse_list.append(mean_squared_error(ytest, y_pred))\n",
        "    r2_list.append(r2_score(ytest, y_pred))\n",
        "    print('Degree of Polynomial Function', degrees[i])\n",
        "    print('Mean squared Error', mse_list[i])\n",
        "    print('Variance Score', r2_list[i])\n",
        "    \n",
        "print(mse_list)\n",
        "print(r2_list)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(degrees, mse_list)\n",
        "plt.xlabel('Degree of Polynomial Function')\n",
        "plt.ylabel('Mean Square Error')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(degrees, r2_list)\n",
        "\n",
        "  \n",
        "plt.xlabel('Degree of Polynomial Function')\n",
        "plt.ylabel('Variance Score')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5yHoNBID-Oc",
        "colab_type": "text"
      },
      "source": [
        "## Comparing different Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhVMPnaX8r5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "num_instances = len(xtrain)\n",
        "\n",
        "models = []\n",
        "models.append(('LiR', LinearRegression()))\n",
        "models.append(('Ridge', Ridge()))\n",
        "models.append(('Lasso', Lasso()))\n",
        "models.append(('ElasticNet', ElasticNet()))\n",
        "models.append(('Bag_Re', BaggingRegressor()))\n",
        "models.append(('RandomForest', RandomForestRegressor()))\n",
        "models.append(('ExtraTreesRegressor', ExtraTreesRegressor()))\n",
        "models.append(('KNN', KNeighborsRegressor()))\n",
        "models.append(('CART', DecisionTreeRegressor()))\n",
        "models.append(('SVM', SVR()))\n",
        "\n",
        "# Evaluations\n",
        "results = []\n",
        "names = []\n",
        "scoring = []\n",
        "\n",
        "for name, model in models:\n",
        "    # Fit the model\n",
        "    model.fit(xtrain, ytrain)\n",
        "    \n",
        "    predictions = model.predict(xtest)\n",
        "    \n",
        "    # Evaluate the model\n",
        "    score = r2_score(ytest, predictions)\n",
        "    mae = mean_squared_error(ytest, predictions)\n",
        "    # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    results.append(mae)\n",
        "    names.append(name)\n",
        "    \n",
        "    msg = \"%s: %f (%f)\" % (name, score, mae)\n",
        "    print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRO8ZP3CPL7Q",
        "colab_type": "text"
      },
      "source": [
        "## Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv-y4iiciANt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = [0.0001, 0.001, 0.02, 0.04, 0.08, 0.16]\n",
        "varScr = []\n",
        "print(alphas)\n",
        "\n",
        "\n",
        "for i in alphas:\n",
        "  regr = linear_model.Lasso(alpha = i)\n",
        "  regr.fit(xtrain, ytrain)\n",
        "  y_pred = regr.predict(xtest)\n",
        "  \n",
        "  r2 = r2_score(ytest, y_pred)\n",
        "  mse = mean_squared_error(ytest, y_pred)\n",
        "  varScr.append(r2)\n",
        "  \n",
        "  print('Alphanr: ', i, ' Mean Squared Error: ', mse, 'Variance Score: ', r2)\n",
        "  fig = plt.figure()\n",
        "  \n",
        "plt.plot(alphas, varScr)\n",
        "plt.xlabel('Regularization Coefficient (lambda)')\n",
        "plt.ylabel('Variance score (varScr)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwahIHq1GZDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}